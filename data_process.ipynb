{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create all combinations of treatments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame 'ir_sham' to '.\\data\\output_preprocess\\ir_sham.csv'\n",
      "Saved DataFrame 'ir_ir+aspirin' to '.\\data\\output_preprocess\\ir_ir+aspirin.csv'\n",
      "Saved DataFrame 'aspirin_sham' to '.\\data\\output_preprocess\\aspirin_sham.csv'\n",
      "Saved DataFrame 'aspirin_ir' to '.\\data\\output_preprocess\\aspirin_ir.csv'\n",
      "Saved DataFrame 'aspirin_ir+aspirin' to '.\\data\\output_preprocess\\aspirin_ir+aspirin.csv'\n",
      "Saved DataFrame 'ir+aspirin_sham' to '.\\data\\output_preprocess\\ir+aspirin_sham.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "def read_data(file_path, sheet_name, save_path):\n",
    "\n",
    "    # Read the specific sheet into a DataFrame\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    ## drop unnecessary columns \n",
    "\n",
    "    columns_to_drop = ['Mouse_ID', 'Tumor_Side', 'Age']\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Specify the treatment type you want to filter by\n",
    "    treatment_type = [0,1,11,10]  \n",
    "\n",
    "    # Filter the DataFrame based on the treatment column\n",
    "    sham_df = df[df['Treatment'] == treatment_type[0]]\n",
    "    sham_df = sham_df.drop(columns= 'Treatment')\n",
    "\n",
    "    ir_df = df[df['Treatment'] == treatment_type[1]]\n",
    "    ir_df = ir_df.drop(columns= 'Treatment')\n",
    "\n",
    "    aspirin_df = df[df['Treatment'] == treatment_type[2]]\n",
    "    aspirin_df = aspirin_df.drop(columns= 'Treatment')\n",
    "\n",
    "    ir_aspirin_df = df[df['Treatment'] == treatment_type[3]]\n",
    "    ir_aspirin_df = ir_aspirin_df.drop(columns= 'Treatment')\n",
    "    # Show the filtered DataFrame\n",
    "    # print(sham_df.head())\n",
    "\n",
    "    # Save column names to a separate file\n",
    "    columns_path = os.path.join(save_path, \"columns.txt\")\n",
    "    with open(columns_path, 'w') as f:\n",
    "        f.write(','.join(df.columns))\n",
    "\n",
    "    return sham_df, ir_df, aspirin_df, ir_aspirin_df\n",
    "\n",
    "\n",
    "def combine_dfs(sham_df, ir_df, aspirin_df, ir_aspirin_df, save_path):\n",
    "    # Store DataFrames in a dictionary for better management\n",
    "    dfs = {\n",
    "        'sham': sham_df,\n",
    "        'ir': ir_df,\n",
    "        'aspirin': aspirin_df,\n",
    "        'ir+aspirin': ir_aspirin_df\n",
    "    }\n",
    "\n",
    "    # Empty list to store results\n",
    "    merged_dataframes = []\n",
    "\n",
    "    # Iterate over pairs of DataFrame names and DataFrames\n",
    "    for name1, df1 in dfs.items():\n",
    "        for name2, df2 in dfs.items():\n",
    "            if name1 < name2:  # This check avoids repeating pairs and self-merging\n",
    "                # Add a new column to each DataFrame to indicate the origin (0 or 1)\n",
    "                df1_modified = df1.copy()\n",
    "                df1_modified['Origin'] = 0  # 0 for rows from the first DataFrame\n",
    "                df1_modified = df1_modified[['Origin'] + [col for col in df1_modified.columns if col != 'Origin']]\n",
    "                \n",
    "                df2_modified = df2.copy()\n",
    "                df2_modified['Origin'] = 1  # 1 for rows from the second DataFrame\n",
    "                df2_modified = df2_modified[['Origin'] + [col for col in df2_modified.columns if col != 'Origin']]\n",
    "                \n",
    "                # Merge the pair of modified DataFrames\n",
    "                merged_df = pd.concat([df1_modified, df2_modified])\n",
    "                \n",
    "                # Store the merged DataFrame with a descriptive name\n",
    "                merged_dataframes.append((f\"{name1}_{name2}\", merged_df))\n",
    "\n",
    "    # Output the results and optionally save them\n",
    "    for name, df in merged_dataframes:\n",
    "        # Save DataFrame to CSV without headers\n",
    "        full_path = os.path.join(save_path, f\"{name}.csv\")\n",
    "        df.to_csv(full_path, index=False, header=False)\n",
    "        print(f\"Saved DataFrame '{name}' to '{full_path}'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = '.\\\\raw_data\\Final_Spreadsheet_separated_by_age.xlsx'\n",
    "sheet_name = 'Age_W5'  # Replace with your actual sheet name\n",
    "save_path = '.\\\\data\\output_preprocess'\n",
    "## creating the source dfs for sham, IR, Aspirin and IR+Aspirin. \n",
    "sham_df, ir_df, aspirin_df, ir_aspirin_df = read_data(file_path, sheet_name, save_path)\n",
    "\n",
    "# Usage example:\n",
    "combine_dfs(sham_df, ir_df, aspirin_df, ir_aspirin_df, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 10 10 10\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(sham_df),len(ir_df), len(aspirin_df), len(ir_aspirin_df))\n",
    "print(len(sham_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding the names of columns to output of r code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved modified data to C:\\Shabani\\Projects\\tumor_latency\\data\\output_r_joint_features\\modified_modified_output_aspirin_ir+aspirin.csv\n",
      "Processed and saved modified data to C:\\Shabani\\Projects\\tumor_latency\\data\\output_r_joint_features\\modified_output_aspirin_ir+aspirin.csv\n",
      "Processed and saved modified data to C:\\Shabani\\Projects\\tumor_latency\\data\\output_r_joint_features\\modified_output_aspirin_ir.csv\n",
      "Processed and saved modified data to C:\\Shabani\\Projects\\tumor_latency\\data\\output_r_joint_features\\modified_output_aspirin_sham.csv\n",
      "Processed and saved modified data to C:\\Shabani\\Projects\\tumor_latency\\data\\output_r_joint_features\\modified_output_ir+aspirin_sham.csv\n",
      "Processed and saved modified data to C:\\Shabani\\Projects\\tumor_latency\\data\\output_r_joint_features\\modified_output_ir_ir+aspirin.csv\n",
      "Processed and saved modified data to C:\\Shabani\\Projects\\tumor_latency\\data\\output_r_joint_features\\modified_output_ir_sham.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def add_feature_names_csv(names_file_path, csv_directory_path, save_directory_path):\n",
    "    # Read names from the file into a list\n",
    "    with open(names_file_path, 'r') as file:\n",
    "        names = [line.strip() for line in file]\n",
    "\n",
    "    # Read CSV files from directory\n",
    "    csv_files = [f for f in os.listdir(csv_directory_path) if f.endswith('.csv')]\n",
    "\n",
    "    # Function to map indices to names\n",
    "    def index_to_name(index):\n",
    "        # Check if index is an integer and within the valid range\n",
    "        if isinstance(index, int) and 1 <= index <= len(names):\n",
    "            return names[index - 1]  # Convert 1-based index to 0-based\n",
    "        else:\n",
    "            return 'Index out of range'\n",
    "\n",
    "    # Process each CSV file\n",
    "    for csv_file in csv_files:\n",
    "        # Read the current CSV file\n",
    "        current_table = pd.read_csv(csv_directory_path + csv_file)\n",
    "        # Convert 'V1' to integers, handling non-convertible values by coercing to NaN\n",
    "        current_table['V1'] = pd.to_numeric(current_table['V1'], errors='coerce').fillna(0).astype(int)\n",
    "        # Map the 'V1' column to names using the provided function\n",
    "        current_table['Names'] = current_table['V1'].apply(index_to_name)\n",
    "\n",
    "        # Save the modified table\n",
    "        modified_file_path = os.path.join(save_directory_path, 'modified_' + csv_file)\n",
    "        current_table.to_csv(modified_file_path, index=False)\n",
    "        print(f\"Processed and saved modified data to {modified_file_path}\")\n",
    "\n",
    "# Example usage of the function:\n",
    "names_file_path = 'C:\\\\Shabani\\\\Projects\\\\tumor_latency\\\\data\\\\column_names.csv'\n",
    "csv_directory_path = 'C:\\\\Shabani\\\\Projects\\\\tumor_latency\\\\data\\\\output_r\\\\'\n",
    "save_directory_path = 'C:\\\\Shabani\\\\Projects\\\\tumor_latency\\\\data\\\\output_r_joint_features\\\\'\n",
    "\n",
    "add_feature_names_csv(names_file_path, csv_directory_path, save_directory_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIC_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
