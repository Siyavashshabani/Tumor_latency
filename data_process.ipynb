{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame 'ir_sham' to '.\\data\\output_preprocess\\ir_sham.csv'\n",
      "Saved DataFrame 'ir_ir+aspirin' to '.\\data\\output_preprocess\\ir_ir+aspirin.csv'\n",
      "Saved DataFrame 'aspirin_sham' to '.\\data\\output_preprocess\\aspirin_sham.csv'\n",
      "Saved DataFrame 'aspirin_ir' to '.\\data\\output_preprocess\\aspirin_ir.csv'\n",
      "Saved DataFrame 'aspirin_ir+aspirin' to '.\\data\\output_preprocess\\aspirin_ir+aspirin.csv'\n",
      "Saved DataFrame 'ir+aspirin_sham' to '.\\data\\output_preprocess\\ir+aspirin_sham.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "def read_data(file_path, sheet_name, save_path):\n",
    "\n",
    "    # Read the specific sheet into a DataFrame\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    ## drop unnecessary columns \n",
    "\n",
    "    columns_to_drop = ['Mouse_ID', 'Tumor_Side', 'Age']\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Specify the treatment type you want to filter by\n",
    "    treatment_type = [0,1,11,10]  \n",
    "\n",
    "    # Filter the DataFrame based on the treatment column\n",
    "    sham_df = df[df['Treatment'] == treatment_type[0]]\n",
    "    sham_df = sham_df.drop(columns= 'Treatment')\n",
    "\n",
    "    ir_df = df[df['Treatment'] == treatment_type[1]]\n",
    "    ir_df = ir_df.drop(columns= 'Treatment')\n",
    "\n",
    "    aspirin_df = df[df['Treatment'] == treatment_type[2]]\n",
    "    aspirin_df = aspirin_df.drop(columns= 'Treatment')\n",
    "\n",
    "    ir_aspirin_df = df[df['Treatment'] == treatment_type[3]]\n",
    "    ir_aspirin_df = ir_aspirin_df.drop(columns= 'Treatment')\n",
    "    # Show the filtered DataFrame\n",
    "    # print(sham_df.head())\n",
    "\n",
    "    # Save column names to a separate file\n",
    "    columns_path = os.path.join(save_path, \"columns.txt\")\n",
    "    with open(columns_path, 'w') as f:\n",
    "        f.write(','.join(df.columns))\n",
    "\n",
    "    return sham_df, ir_df, aspirin_df, ir_aspirin_df\n",
    "\n",
    "\n",
    "def combine_dfs(sham_df, ir_df, aspirin_df, ir_aspirin_df, save_path):\n",
    "    # Store DataFrames in a dictionary for better management\n",
    "    dfs = {\n",
    "        'sham': sham_df,\n",
    "        'ir': ir_df,\n",
    "        'aspirin': aspirin_df,\n",
    "        'ir+aspirin': ir_aspirin_df\n",
    "    }\n",
    "\n",
    "    # Empty list to store results\n",
    "    merged_dataframes = []\n",
    "\n",
    "    # Iterate over pairs of DataFrame names and DataFrames\n",
    "    for name1, df1 in dfs.items():\n",
    "        for name2, df2 in dfs.items():\n",
    "            if name1 < name2:  # This check avoids repeating pairs and self-merging\n",
    "                # Add a new column to each DataFrame to indicate the origin (0 or 1)\n",
    "                df1_modified = df1.copy()\n",
    "                df1_modified['Origin'] = 0  # 0 for rows from the first DataFrame\n",
    "                df1_modified = df1_modified[['Origin'] + [col for col in df1_modified.columns if col != 'Origin']]\n",
    "                \n",
    "                df2_modified = df2.copy()\n",
    "                df2_modified['Origin'] = 1  # 1 for rows from the second DataFrame\n",
    "                df2_modified = df2_modified[['Origin'] + [col for col in df2_modified.columns if col != 'Origin']]\n",
    "                \n",
    "                # Merge the pair of modified DataFrames\n",
    "                merged_df = pd.concat([df1_modified, df2_modified])\n",
    "                \n",
    "                # Store the merged DataFrame with a descriptive name\n",
    "                merged_dataframes.append((f\"{name1}_{name2}\", merged_df))\n",
    "\n",
    "    # Output the results and optionally save them\n",
    "    for name, df in merged_dataframes:\n",
    "        # Save DataFrame to CSV without headers\n",
    "        full_path = os.path.join(save_path, f\"{name}.csv\")\n",
    "        df.to_csv(full_path, index=False, header=False)\n",
    "        print(f\"Saved DataFrame '{name}' to '{full_path}'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = '.\\\\raw_data\\Final_Spreadsheet_separated_by_age.xlsx'\n",
    "sheet_name = 'Age_W5'  # Replace with your actual sheet name\n",
    "save_path = '.\\\\data\\output_preprocess'\n",
    "## creating the source dfs for sham, IR, Aspirin and IR+Aspirin. \n",
    "sham_df, ir_df, aspirin_df, ir_aspirin_df = read_data(file_path, sheet_name, save_path)\n",
    "\n",
    "# Usage example:\n",
    "combine_dfs(sham_df, ir_df, aspirin_df, ir_aspirin_df, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 10 10 10\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(sham_df),len(ir_df), len(aspirin_df), len(ir_aspirin_df))\n",
    "print(len(sham_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding the names of columns to output of r code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    V1          V2         V3          V4          V5             V6  \\\n",
      "0    2  -14.103498   0.758340  -15.589817  -12.617179     345.880202   \n",
      "1    3   18.291639   0.581321   17.152272   19.431007     990.087961   \n",
      "2    4 -506.956163  26.637416 -559.164539 -454.747786     362.206818   \n",
      "3    5   82.266591   1.516651   79.294009   85.239172    2942.223950   \n",
      "4    9 -248.859346   2.919214 -254.580901 -243.137791    7267.347350   \n",
      "5   14  102.411078   0.816817  100.810147  104.012009   15719.719058   \n",
      "6   15   -0.007660   0.417750   -0.826435    0.811115       0.000336   \n",
      "7   16  -42.858815   0.467386  -43.774874  -41.942755    8408.702062   \n",
      "8   17    0.037758   0.598427   -1.135137    1.210652       0.003981   \n",
      "9   20  -13.148926   0.740068  -14.599433  -11.698418     315.672481   \n",
      "10  21  -74.575038   1.431405  -77.380541  -71.769535    2714.324075   \n",
      "11  23  115.877230   0.284099  115.320407  116.434053  166363.407834   \n",
      "12  24   -0.761578  11.644679  -23.584728   22.061573       0.004277   \n",
      "13  25   16.079631   0.485922   15.127242   17.032021    1095.012536   \n",
      "14  26  -18.226953   0.536689  -19.278844  -17.175062    1153.407782   \n",
      "15  27    0.139791   0.023866    0.093014    0.186568      34.307180   \n",
      "16  28    1.031592   0.034813    0.963360    1.099824     878.093518   \n",
      "\n",
      "               V7               Names  \n",
      "0    3.344252e-77  Index out of range  \n",
      "1   2.563283e-217  Index out of range  \n",
      "2    9.312361e-81  Index out of range  \n",
      "3    0.000000e+00  Index out of range  \n",
      "4    0.000000e+00  Index out of range  \n",
      "5    0.000000e+00  Index out of range  \n",
      "6    9.853706e-01  Index out of range  \n",
      "7    0.000000e+00  Index out of range  \n",
      "8    9.496907e-01  Index out of range  \n",
      "9    1.269254e-70  Index out of range  \n",
      "10   0.000000e+00  Index out of range  \n",
      "11   0.000000e+00  Index out of range  \n",
      "12   9.478544e-01  Index out of range  \n",
      "13  4.007596e-240  Index out of range  \n",
      "14  8.151833e-253  Index out of range  \n",
      "15   4.706421e-09  Index out of range  \n",
      "16  5.676645e-193  Index out of range  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the .txt file containing names\n",
    "names_file_path = 'C:\\\\Shabani\\\\Projects\\\\tumor_latency\\data\\\\output_preprocess\\\\columns.txt'\n",
    "# Path to the directory containing the CSV files\n",
    "csv_directory_path = 'C:\\\\Shabani\\\\Projects\\\\tumor_latency\\\\data\\\\output_r\\\\'\n",
    "\n",
    "# Read names from the .txt file into a list\n",
    "with open(names_file_path, 'r') as file:\n",
    "    names = file.read().splitlines()\n",
    "\n",
    "# Read CSV files\n",
    "csv_files = [f for f in os.listdir(csv_directory_path) if f.endswith('.csv')]\n",
    "\n",
    "# Read the first CSV file to modify\n",
    "first_table = pd.read_csv(csv_directory_path + csv_files[0])\n",
    "\n",
    "# Map the 'V1' column to names using the list from the .txt file\n",
    "# Ensure that the indexes in 'V1' are valid indexes in the names list\n",
    "first_table['Names'] = first_table['V1'].apply(lambda x: names[x-1] if x <= len(names) else 'Index out of range')\n",
    "\n",
    "# Save or display the modified table\n",
    "print(first_table)  # Print the DataFrame\n",
    "# Optionally, save back to csv\n",
    "first_table.to_csv(csv_directory_path + 'modified_' + csv_files[0], index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    V1          V2         V3          V4          V5             V6  \\\n",
      "0    2  -14.103498   0.758340  -15.589817  -12.617179     345.880202   \n",
      "1    3   18.291639   0.581321   17.152272   19.431007     990.087961   \n",
      "2    4 -506.956163  26.637416 -559.164539 -454.747786     362.206818   \n",
      "3    5   82.266591   1.516651   79.294009   85.239172    2942.223950   \n",
      "4    9 -248.859346   2.919214 -254.580901 -243.137791    7267.347350   \n",
      "5   14  102.411078   0.816817  100.810147  104.012009   15719.719058   \n",
      "6   15   -0.007660   0.417750   -0.826435    0.811115       0.000336   \n",
      "7   16  -42.858815   0.467386  -43.774874  -41.942755    8408.702062   \n",
      "8   17    0.037758   0.598427   -1.135137    1.210652       0.003981   \n",
      "9   20  -13.148926   0.740068  -14.599433  -11.698418     315.672481   \n",
      "10  21  -74.575038   1.431405  -77.380541  -71.769535    2714.324075   \n",
      "11  23  115.877230   0.284099  115.320407  116.434053  166363.407834   \n",
      "12  24   -0.761578  11.644679  -23.584728   22.061573       0.004277   \n",
      "13  25   16.079631   0.485922   15.127242   17.032021    1095.012536   \n",
      "14  26  -18.226953   0.536689  -19.278844  -17.175062    1153.407782   \n",
      "15  27    0.139791   0.023866    0.093014    0.186568      34.307180   \n",
      "16  28    1.031592   0.034813    0.963360    1.099824     878.093518   \n",
      "\n",
      "               V7               Names  \n",
      "0    3.344252e-77  Index out of range  \n",
      "1   2.563283e-217  Index out of range  \n",
      "2    9.312361e-81  Index out of range  \n",
      "3    0.000000e+00  Index out of range  \n",
      "4    0.000000e+00  Index out of range  \n",
      "5    0.000000e+00  Index out of range  \n",
      "6    9.853706e-01  Index out of range  \n",
      "7    0.000000e+00  Index out of range  \n",
      "8    9.496907e-01  Index out of range  \n",
      "9    1.269254e-70  Index out of range  \n",
      "10   0.000000e+00  Index out of range  \n",
      "11   0.000000e+00  Index out of range  \n",
      "12   9.478544e-01  Index out of range  \n",
      "13  4.007596e-240  Index out of range  \n",
      "14  8.151833e-253  Index out of range  \n",
      "15   4.706421e-09  Index out of range  \n",
      "16  5.676645e-193  Index out of range  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the .txt file containing names\n",
    "names_file_path = 'C:\\\\Shabani\\\\Projects\\\\tumor_latency\\\\data\\\\output_preprocess\\\\columns.txt'\n",
    "# Path to the directory containing the CSV files\n",
    "csv_directory_path = 'C:\\\\Shabani\\\\Projects\\\\tumor_latency\\\\data\\\\output_r\\\\'\n",
    "\n",
    "# Read names from the .txt file into a list\n",
    "with open(names_file_path, 'r') as file:\n",
    "    names = file.read().splitlines()\n",
    "\n",
    "# Read CSV files\n",
    "csv_files = [f for f in os.listdir(csv_directory_path) if f.endswith('.csv')]\n",
    "\n",
    "# Read the first CSV file to modify\n",
    "first_table = pd.read_csv(csv_directory_path + csv_files[0])\n",
    "\n",
    "# Function to map indices to names\n",
    "def index_to_name(index):\n",
    "    # Check if index is an integer and within the valid range\n",
    "    if isinstance(index, int) and 1 <= index <= len(names):\n",
    "        return names[index - 1]  # Convert 1-based index to 0-based\n",
    "    else:\n",
    "        return 'Index out of range'\n",
    "\n",
    "# Map the 'V1' column to names\n",
    "first_table['Names'] = first_table['V1'].apply(index_to_name)\n",
    "\n",
    "# Save or display the modified table\n",
    "print(first_table)  # Print the DataFrame\n",
    "# Optionally, save back to csv\n",
    "first_table.to_csv(csv_directory_path + 'modified_' + csv_files[0], index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIC_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
